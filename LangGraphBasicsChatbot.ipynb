{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfSb0QWsQ6OnNeioV8y9xX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LRManamperi/Machine-Learning/blob/main/LangGraphBasicsChatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xC7XjYy3Y24a"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "\n",
        "_set_env(\"ANTHROPIC_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1v3df87ZlvC",
        "outputId": "ba3fa3a1-1307-423e-8329-95846845c443"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANTHROPIC_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "xdurhaEaZqXL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "mXVxtBHoZxjQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "# The first argument is the unique node name\n",
        "# The second argument is the function or object that will be called whenever\n",
        "# the node is used.\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-A_myRdaArZ",
        "outputId": "d971f94b-6351-4fb6-93a1-48e8e6250390"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x790f1fdc3450>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START, \"chatbot\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBhmgyZgaI6F",
        "outputId": "2afbf7a9-75e5-46b3-d372-76f6d50d9905"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x790f1fdc3450>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(\"chatbot\", END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cHNKrAzaSzB",
        "outputId": "99a2fe43-289a-446d-ef66-d89e7522b1b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x790f1fdc3450>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "vHUknbyeaXNC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "yUHNv3yQabdZ",
        "outputId": "78525bbb-75a1-4eeb-d6c0-51ef51b5caeb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        for value in event.values():\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "c78jfFCfahQA",
        "outputId": "892a2354-5f71-4db2-c323-76b95536dff7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: \n",
            "User: What do you know about LangGraph?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7f1286ff1e1a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"What do you know about LangGraph?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mstream_graph_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-7f1286ff1e1a>\u001b[0m in \u001b[0;36mstream_graph_updates\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstream_graph_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Assistant:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2431\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2432\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2433\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2434\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2435\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-94bcc5450d2b>\u001b[0m in \u001b[0;36mchatbot\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m         return cast(\n\u001b[1;32m    367\u001b[0m             \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    369\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    936\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m                 results.append(\n\u001b[0;32m--> 759\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    760\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1003\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_anthropic/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_request_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anthropic/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anthropic/resources/messages/messages.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, max_tokens, messages, model, metadata, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    946\u001b[0m             )\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    949\u001b[0m             \u001b[0;34m\"/v1/messages\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         )\n\u001b[0;32m-> 1279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U tavily-python langchain_community"
      ],
      "metadata": {
        "id": "QPWaW-TfbIHa"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
        "# Modification: tell the LLM which tools it can call\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "09oUwsDEcDWt",
        "outputId": "a38018b2-7169-44a2-fcfe-a3fc2ce52845"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tools' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-77e6e8e10800>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatAnthropic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"claude-3-5-sonnet-20240620\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Modification: tell the LLM which tools it can call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mllm_with_tools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tools' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "\n",
        "class BasicToolNode:\n",
        "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
        "\n",
        "    def __init__(self, tools: list) -> None:\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "    def __call__(self, inputs: dict):\n",
        "        if messages := inputs.get(\"messages\", []):\n",
        "            message = messages[-1]\n",
        "        else:\n",
        "            raise ValueError(\"No message found in input\")\n",
        "        outputs = []\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "                tool_call[\"args\"]\n",
        "            )\n",
        "            outputs.append(\n",
        "                ToolMessage(\n",
        "                    content=json.dumps(tool_result),\n",
        "                    name=tool_call[\"name\"],\n",
        "                    tool_call_id=tool_call[\"id\"],\n",
        "                )\n",
        "            )\n",
        "        return {\"messages\": outputs}\n",
        "\n",
        "\n",
        "tool_node = BasicToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "3W0hdTCaa5Eb",
        "outputId": "86aece8e-6d6f-4c96-9b65-78dde5473b8e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tool' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f349dd027205>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtool_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBasicToolNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mgraph_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tools\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tool' is not defined"
          ]
        }
      ]
    }
  ]
}