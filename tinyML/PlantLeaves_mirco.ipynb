{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LRManamperi/Machine-Learning/blob/main/tinyML/PlantLeaves_mirco.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc-BhdKnJRsJ"
      },
      "source": [
        "####  **Importing Required Libraries**\n",
        "\n",
        "**Objective**  \n",
        "This section introduces the libraries and modules required for this lab. These libraries enable efficient data handling, preprocessing, and model building for TinyML applications.\n",
        "\n",
        "**Key Components**  \n",
        "- **TensorFlow**: A powerful framework for building and deploying machine learning models, especially suited for deep learning tasks.  \n",
        "- **TensorFlow Datasets (TFDS)**: A module to download and preprocess datasets like PlantVillage efficiently.  \n",
        "- **Keras Layers and Models**: Used to customize the architecture for our binary classification task.  \n",
        "- **Adam Optimizer**: A widely-used optimization algorithm for training neural networks efficiently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vy0nmn4s9oK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00801d93-7537-4739-ba47-8d1f60861461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "# Tip: You may need to grant permission in Colab; rerun if path errors occur.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y keras tensorflow tensorflow-model-optimization\n",
        "!pip install tensorflow==2.12 tensorflow-model-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ik3NfKVDrj60",
        "outputId": "85820ad8-1903-47bb-f583-52ef3fcd0e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: keras 3.10.0\n",
            "Uninstalling keras-3.10.0:\n",
            "  Successfully uninstalled keras-3.10.0\n",
            "Found existing installation: tensorflow 2.19.0\n",
            "Uninstalling tensorflow-2.19.0:\n",
            "  Successfully uninstalled tensorflow-2.19.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-model-optimization as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting tensorflow==2.12\n",
            "  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (25.2.10)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.74.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.14.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.5.3)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (25.0)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.12)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.17.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (4.14.1)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12)\n",
            "  Downloading wrapt-1.14.2-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.37.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (0.1.9)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.45.1)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (25.3.0)\n",
            "Requirement already satisfied: jaxlib<=0.5.3,>=0.5.3 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.5.3)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.5.3)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.7.0,>=0.7.0 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.7.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.6.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.2,>=0.6.2 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.6.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.1,>=0.6.1 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.6.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.6.0,>=0.6.0 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.5.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.2,>=0.5.1 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.5.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.0,>=0.5.0 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.37,>=0.4.36 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.33,>=0.4.33 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.33-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.31-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.16.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2025.8.3)\n",
            "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting scipy>=1.9 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading scipy-1.16.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.3.1)\n",
            "Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.2-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, gast, scipy, tensorflow-model-optimization, jaxlib, google-auth-oauthlib, tensorboard, jax, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.1\n",
            "    Uninstalling scipy-1.16.1:\n",
            "      Successfully uninstalled scipy-1.16.1\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.3\n",
            "    Uninstalling jaxlib-0.5.3:\n",
            "      Successfully uninstalled jaxlib-0.5.3\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.19.0\n",
            "    Uninstalling tensorboard-2.19.0:\n",
            "      Successfully uninstalled tensorboard-2.19.0\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.3\n",
            "    Uninstalling jax-0.5.3:\n",
            "      Successfully uninstalled jax-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.19.0 requires tensorflow<2.20,>=2.19, but you have tensorflow 2.12.0 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 2.14.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "pywavelets 1.9.0 requires numpy<3,>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.90 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "geopandas 1.1.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "contourpy 1.3.3 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "keras-hub 0.21.1 requires keras>=3.5, but you have keras 2.12.0 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "orbax-checkpoint 0.11.21 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "treescope 0.1.10 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "pymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 numpy-1.23.5 protobuf-4.25.8 scipy-1.15.3 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-model-optimization-0.8.0 wrapt-1.14.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "a40067aa01a34648a3c28d23daa5cb5b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Iicar-k-vjv"
      },
      "outputs": [],
      "source": [
        "save_dir = '/content/drive/My Drive/TinyPlants'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSr3GAUbEXaD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "987badc8-f12f-4d57-d537-041bc56436d0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-761874917.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMobileNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Bring in subpackages.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# from tensorflow.python import keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/service/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    417\u001b[0m \"\"\"\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_service_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompression_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_server_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/ops/compression_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# ==============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_experimental_dataset_ops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mged_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrapt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/util/nest.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \"\"\"\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sparse_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/sparse_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_conversion_registry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfast_tensor_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   \u001b[0m_FAST_TENSOR_UTIL_AVAILABLE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mtensorflow/python/framework/fast_tensor_util.pyx\u001b[0m in \u001b[0;36minit tensorflow.python.framework.fast_tensor_util\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2XYx35lJatR"
      },
      "source": [
        "#### **Preparing the PlantVillage Dataset**\n",
        "\n",
        "**Objective**  \n",
        "This section focuses on loading, preprocessing, and splitting the PlantVillage dataset into training, validation, and test sets while converting it into a binary classification dataset.\n",
        "\n",
        "**Steps**  \n",
        "1. **Load the Dataset**: Utilize TensorFlow Datasets (TFDS) to download and load the PlantVillage dataset.  \n",
        "2. **Define Healthy Classes**: Specify the \"healthy\" classes from the dataset's class list. All other classes are automatically labeled as \"unhealthy.\"  \n",
        "3. **Relabel the Dataset**: Implement a mapping function to convert multi-class labels into binary labels (`0` for healthy, `1` for unhealthy).  \n",
        "4. **Split the Dataset**: Divide the dataset into training (40,000 samples), validation (7,000 samples), and test sets.  \n",
        "5. **Preprocess Images**: Resize images to the input size expected by MobileNet and normalize pixel values to the range [0, 1].\n",
        "\n",
        "**Outcome**  \n",
        "This step produces preprocessed datasets ready for training, validation, and evaluation, tailored for binary classification tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the PlantVillage dataset\n",
        "dataset, info = tfds.load('plant_village', with_info=True, as_supervised=True)\n",
        "\n",
        "# Define the \"healthy\" classes\n",
        "healthy_classes = [\n",
        "    'Apple___healthy', 'Blueberry___healthy', 'Cherry___healthy',\n",
        "    'Corn___healthy', 'Grape___healthy', 'Peach___healthy',\n",
        "    'Pepper,_bell___healthy', 'Potato___healthy', 'Raspberry___healthy',\n",
        "    'Soybean___healthy', 'Strawberry___healthy', 'Tomato___healthy'\n",
        "]\n",
        "\n",
        "# Get class names from the dataset info\n",
        "class_names = info.features['label'].names"
      ],
      "metadata": {
        "id": "sYQ1qR7ROhCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrected function to map original labels to binary labels\n",
        "def map_to_binary_label(image, label):\n",
        "    class_name = tf.gather(class_names, tf.cast(label, tf.int32))  # Convert label to int and get class name\n",
        "    new_label = tf.cond(\n",
        "        tf.reduce_any(tf.equal(class_name, healthy_classes)),\n",
        "        lambda: tf.constant(0),  # Healthy\n",
        "        lambda: tf.constant(1)   # Unhealthy\n",
        "    )\n",
        "    return image, new_label\n",
        "\n",
        "binary_train_dataset = dataset['train'].map(map_to_binary_label)"
      ],
      "metadata": {
        "id": "ux9KhG6GQBI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-Y4G7S0EwWl"
      },
      "outputs": [],
      "source": [
        "# Load the PlantVillage dataset\n",
        "dataset, info = tfds.load('plant_village', with_info=True, as_supervised=True)\n",
        "\n",
        "# Define the \"healthy\" classes\n",
        "healthy_classes = [\n",
        "    'Apple___healthy', 'Blueberry___healthy', 'Cherry___healthy',\n",
        "    'Corn___healthy', 'Grape___healthy', 'Peach___healthy',\n",
        "    'Pepper,_bell___healthy', 'Potato___healthy', 'Raspberry___healthy',\n",
        "    'Soybean___healthy', 'Strawberry___healthy', 'Tomato___healthy'\n",
        "]\n",
        "\n",
        "# Get class names from the dataset info\n",
        "class_names = info.features['label'].names\n",
        "\n",
        "# Function to map original labels to binary labels\n",
        "def map_to_binary_label(image, label):\n",
        "    class_name = class_names[label]\n",
        "    if class_name in healthy_classes:\n",
        "        new_label = 0  # Healthy\n",
        "    else:\n",
        "        new_label = 1  # Unhealthy\n",
        "    return image, new_label\n",
        "\n",
        "# Corrected function to map original labels to binary labels\n",
        "def map_to_binary_label(image, label):\n",
        "    class_name = tf.gather(class_names, tf.cast(label, tf.int32))  # Convert label to int and get class name\n",
        "    new_label = tf.cond(\n",
        "        tf.reduce_any(tf.equal(class_name, healthy_classes)),\n",
        "        lambda: tf.constant(0),  # Healthy\n",
        "        lambda: tf.constant(1)   # Unhealthy\n",
        "    )\n",
        "    return image, new_label\n",
        "\n",
        "# Apply the corrected mapping function\n",
        "binary_train_dataset = dataset['train'].map(map_to_binary_label)\n",
        "\n",
        "\n",
        "# Split into training, validation, and test sets\n",
        "train_dataset = binary_train_dataset.take(40000)\n",
        "val_dataset = binary_train_dataset.skip(40000).take(7000)\n",
        "test_dataset = binary_train_dataset.skip(47000)\n",
        "\n",
        "# Image preprocessing\n",
        "IMG_SIZE = (64, 64)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def preprocess_image(image, label):\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    image = image / 255.0  # Normalize to [0,1] range\n",
        "    return image, label\n",
        "\n",
        "# Preprocess the datasets\n",
        "train_dataset = train_dataset.map(preprocess_image).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW9iZxvJJhf2"
      },
      "source": [
        "#### **Visualizing Healthy and Unhealthy Leaves**\n",
        "\n",
        "**Objective**  \n",
        "This section introduces a visualization step to better understand the dataset. It plots examples of healthy and unhealthy plant leaves from the training dataset.\n",
        "\n",
        "**Steps**  \n",
        "1. **Helper Functions**:  \n",
        "   - `plot_images`: Displays a grid of images with labels.  \n",
        "   - `collect_examples`: Extracts a specified number of healthy and unhealthy images for visualization.  \n",
        "2. **Visualization**: Visualize 5 healthy and 5 unhealthy plant leaves from the training dataset.  \n",
        "   - Healthy leaves are labeled as `Healthy`.  \n",
        "   - Unhealthy leaves are labeled as `Unhealthy`.\n",
        "\n",
        "**Outcome**  \n",
        "This step helps participants familiarize themselves with the dataset and ensures the binary labeling was applied correctly. It also emphasizes the importance of understanding the dataset before training a model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMYuSJFoGSwm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Helper function to display images with labels\n",
        "def plot_images(images, labels, title):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    for i in range(len(images)):\n",
        "        plt.subplot(2, 5, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.title('Healthy' if labels[i] == 0 else 'Unhealthy')\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "# Function to collect 5 healthy and 5 unhealthy examples\n",
        "def collect_examples(dataset, num_per_class=5):\n",
        "    healthy_images = []\n",
        "    unhealthy_images = []\n",
        "    for image, label in dataset.unbatch():  # Unbatch to iterate over individual samples\n",
        "        if len(healthy_images) < num_per_class and label.numpy() == 0:\n",
        "            healthy_images.append(image.numpy())\n",
        "        elif len(unhealthy_images) < num_per_class and label.numpy() == 1:\n",
        "            unhealthy_images.append(image.numpy())\n",
        "        # Stop once we have enough examples\n",
        "        if len(healthy_images) == num_per_class and len(unhealthy_images) == num_per_class:\n",
        "            break\n",
        "    return healthy_images, unhealthy_images\n",
        "\n",
        "# Collect examples from the training dataset\n",
        "healthy_images, unhealthy_images = collect_examples(train_dataset)\n",
        "\n",
        "# Plot healthy and unhealthy images\n",
        "plot_images(healthy_images, [0] * len(healthy_images), title=\"Healthy Plant Leaves\")\n",
        "plot_images(unhealthy_images, [1] * len(unhealthy_images), title=\"Unhealthy Plant Leaves\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kfk3l2RKd5u"
      },
      "source": [
        "# A Simple CNN with Mixed Precision for Binary Classification\n",
        "\n",
        "## Objective\n",
        "This section focuses on building a simple CNN model with mixed precision to classify plant leaves as healthy or unhealthy. Mixed precision allows faster computation and reduced memory usage by leveraging the efficiency of lower-precision arithmetic.\n",
        "\n",
        "\n",
        "\n",
        "## Steps\n",
        "\n",
        "1. **Create CNN Model**: Create a simple CNN with few convolusion layers and inut layer matching dimensions for a 64*64 image and output lyaer wiht 2 neurons as thi is a binary classification.\n",
        "\n",
        "2. **Compile the Model**: Use the Adam optimizer with a learning rate of 0.001, binary cross-entropy loss function, and accuracy as a performance metric.\n",
        "\n",
        "3. **Optimize Dataset Pipeline**: Use TensorFlow's `tf.data` API to prefetch data, ensuring efficient data loading during training and validation.\n",
        "\n",
        "4. **Train the Model**: Train the model using the prepared training and validation datasets for 10 epochs. The mixed precision policy improves training speed on supported hardware.\n",
        "\n",
        "5. **Evaluate the Model**: Test the model on the test dataset to evaluate its performance and display the test accuracy.\n",
        "\n",
        "6. **Save the Model**: Save the trained CNN model in the recommended `.keras` format for future deployment or inference tasks.\n",
        "\n",
        "## Outcome\n",
        "By the end of this section, participants will have:\n",
        "- Trained a compact, efficient model optimized for TinyML applications.\n",
        "- Leveraged mixed precision training for faster computation and reduced memory consumption without compromising model accuracy.\n",
        "- Saved the trained model in a modern format for deployment on resource-constrained devices.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Input, Rescaling, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Use float32 for clean INT8 PTQ conversion\n",
        "tf.keras.mixed_precision.set_global_policy('float32') #make sure all weights and biased are in 'float32'\n",
        "\n",
        "input_shape = (64, 64, 3)\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=input_shape),\n",
        "    Rescaling(1./255.0),             # bake in normalization\n",
        "    Conv2D(8, 3, activation='relu', padding='valid'),\n",
        "    MaxPooling2D(2),\n",
        "    Conv2D(16, 3, activation='relu', padding='valid'),\n",
        "    MaxPooling2D(2),\n",
        "    Flatten(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')    # binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "J6fnvN82KD1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHUyWevbczuT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=5\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Save the model in Keras format\n",
        "model.save(os.path.join(save_dir,'mobilenet_finetuned_binary_plant_village.keras'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ8-IkxVO2EF"
      },
      "source": [
        "## Saving the Model to Google Drive\n",
        "\n",
        "This section demonstrates how to save the fine-tuned MobileNetV2 model to a folder named `TinyPlants` in your Google Drive. By following these steps, you can ensure that the trained model is stored securely and can be accessed later for deployment or further experimentation.\n",
        "\n",
        "### Steps:\n",
        "1. **Mount Google Drive**: Connect your Google Drive to the Colab environment to enable file saving and retrieval.\n",
        "2. **Create Folder**: Check if the `TinyPlants` folder exists in your Google Drive. If not, create it automatically.\n",
        "3. **Save the Model**: Save the fine-tuned model in the `.keras` format to the `TinyPlants` folder for easy organization and access.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xN-lrjeOmwy"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CysjvqzaOnF5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Save the model in Keras format to the specified directory\n",
        "# Define Google Drive save paths in the TinyPlants folder\n",
        "save_dir = '/content/drive/My Drive/TinyPlants'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "model_path = os.path.join(save_dir, 'binary_plant_village.keras')\n",
        "model.save(model_path)\n",
        "\n",
        "print(f\"Model saved to {model_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJJH8ulnPZjd"
      },
      "source": [
        "## Converting the Model to TensorFlow Lite with Integer Quantization\n",
        "\n",
        "This section demonstrates how to convert the trained Keras model into a TensorFlow Lite model with integer quantization, ensuring that the input tensors have the correct dimensions required for TensorFlow Lite. Integer quantization optimizes the model for deployment on resource-constrained devices, like microcontrollers, while maintaining accuracy.\n",
        "\n",
        "### Key Steps:\n",
        "\n",
        "1. **Representative Dataset**:\n",
        "   - A subset of the training data is used to calibrate the quantization process, ensuring accurate scaling of weights and activations during integer quantization.\n",
        "\n",
        "2. **Correct Input Shape for Representative Dataset**:\n",
        "   - TensorFlow Lite requires inputs to have a batch dimension, making the input shape `[batch_size, height, width, channels]`.\n",
        "   - This issue is addressed by using `tf.expand_dims()` to add a batch dimension to the images in the representative dataset.\n",
        "\n",
        "3. **Conversion Process**:\n",
        "   - The TensorFlow Lite converter is configured to use integer quantization (`TFLITE_BUILTINS_INT8`) and fallback to TensorFlow operations (`SELECT_TF_OPS`) for unsupported layers.\n",
        "\n",
        "4. **Save the Quantized Model**:\n",
        "   - The quantized model is saved as `mobilenet_quantized_binary_plant_village.tflite` for deployment.\n",
        "\n",
        "### Benefits of Integer Quantization:\n",
        "- Reduces model size and memory usage, making it suitable for TinyML applications.\n",
        "- Increases inference speed on devices with hardware acceleration for integer arithmetic.\n",
        "- Maintains high accuracy through proper calibration using the representative dataset.\n",
        "\n",
        "By the end of this section, the CNN model is converted into a lightweight, quantized format, ready for deployment on edge devices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk-XtEYsOrCX"
      },
      "source": [
        "\n",
        "## Why we need a Representative Dataset\n",
        "When you quantize a model, you’re reducing the numerical precision of:\n",
        "- **Weights** (e.g., from `float32` → `int8`)\n",
        "- **Activations / intermediate feature maps** (e.g., `float32` → `int8`)\n",
        "\n",
        "To do that properly, TensorFlow Lite needs to figure out:\n",
        "- The **range of values** that each tensor can take during inference (`min` and `max`)\n",
        "- How to map those ranges into an 8-bit integer range (`-128` to `127` for signed int8)\n",
        "\n",
        "\n",
        "## How the representative dataset is used\n",
        "- The representative dataset is passed through the model **once during conversion** (not training).\n",
        "- TFLite observes the **distribution of activations** at each layer.\n",
        "- It then chooses an appropriate **scale factor** and **zero point** for each tensor.\n",
        "- This calibration ensures that the model’s integer arithmetic closely approximates the original floating-point behavior.\n",
        "\n",
        "**Without a representative dataset:**\n",
        "- Tensor ranges might be guessed poorly (e.g., all layers get the same generic range).\n",
        "- Quantization error could blow up, leading to a **huge drop in accuracy**.\n",
        "\n",
        "\n",
        "## How good does it need to be?\n",
        "- It **doesn’t need to be large**—usually 100–500 samples is enough.\n",
        "- It **should reflect the real-world input distribution** your model will see.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZV6mRvwOrjb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the .keras model\n",
        "#model = tf.keras.models.load_model(os.path.join(save_dir,'binary_plant_village.keras'))\n",
        "\n",
        "# Define the representative dataset for quantization\n",
        "def representative_dataset():\n",
        "    for image, _ in train_dataset.unbatch().take(100):  # Take 100 samples from training data\n",
        "        image = tf.expand_dims(image, axis=0)  # Add a batch dimension\n",
        "        yield [tf.cast(image, tf.float32)]\n",
        "\n",
        "# Convert the loaded Keras model to TensorFlow Lite format with integer quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.experimental_new_converter = True\n",
        "# Enable fallback to allow unsupported ops to use float\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8,  # Use integer ops when possible\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,          # allow float    # Fallback to TensorFlow ops if needed\n",
        "]\n",
        "\n",
        "converter.inference_input_type = tf.int8  # Quantize input to int8\n",
        "#converter.inference_output_type = tf.int8  # Quantize output to int8\n",
        "\n",
        "# Convert the model\n",
        "quantized_model = converter.convert()\n",
        "\n",
        "# Save the quantized model\n",
        "quantized_model_path = os.path.join(save_dir,'quantized_binary_plant_village.tflite')\n",
        "with open(quantized_model_path, 'wb') as f:\n",
        "    f.write(quantized_model)\n",
        "\n",
        "print(f\"Quantized model saved as '{quantized_model_path}'\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect TFLite Ops: Is the Model Fully Deployable (No TF Fallback)?\n",
        "\n",
        "**What this cell does**\n",
        "- **Loads a `.tflite` model** from disk into a `tf.lite.Interpreter`.\n",
        "- **Lists all operators** used in the model via `interpreter._get_ops_details()`.\n",
        "- **Flags TensorFlow fallback ops** (`SELECT_TF_OPS` / Flex).  \n",
        "  - If any fallback ops are present, the model is **not** purely TFLite-builtins and **won’t** run on runtimes that require only builtins (e.g., TFLite Micro on many microcontrollers).\n",
        "  - If **no** fallback ops are present, all ops are native TFLite builtins—**good for embedded deployment**.\n",
        "\n",
        "**Why this matters**\n",
        "- **Full TFLite builtin coverage** is required for microcontroller targets (TFLite Micro).  \n",
        "- Models that rely on `SELECT_TF_OPS` need the larger TF runtime and are typically unsuitable for TinyML deployments.\n",
        "\n",
        "**Printed output**\n",
        "- A numbered list of ops like:\n",
        "  - `Op 0: CONV_2D (TFLite Builtin)`\n",
        "  - `Op 1: SELECT_TF_OP_* (Fallback to TensorFlow)`\n",
        "- A final message stating whether the model includes TF fallback ops.\n",
        "\n",
        "**Notes & limitations**\n",
        "- This check focuses on **operator support**, not tensor **data types**:\n",
        "  - To verify **full INT8 quantization**, also inspect:\n",
        "    - `interpreter.get_input_details()` / `get_output_details()` to ensure `dtype == int8` and valid `(scale, zero_point)`.\n",
        "    - `interpreter.get_tensor_details()` to confirm intermediates are quantized (look for quantization params).\n",
        "- `interpreter._get_ops_details()` is a **private** API and may change across TF versions. Alternatives:\n",
        "  - `tf.lite.experimental.Analyzer.analyze_model()` for a human-readable graph report.\n",
        "  - Parse the FlatBuffer with the TFLite schema if you need a stable programmatic approach.\n",
        "\n",
        "**Bottom line**\n",
        "- **No `SELECT_TF_OPS` found** → the model is **builtins-only** and generally **deployable on microcontrollers**.  \n",
        "- **Any `SELECT_TF_OPS` present** → not fully TFLite-native; **full INT8 TinyML deployment is unlikely** without modifying the model.\n"
      ],
      "metadata": {
        "id": "vml_AIQI3VXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import flatbuffers\n",
        "import os\n",
        "\n",
        "from tensorflow.lite.python import interpreter as interpreter_wrapper\n",
        "from tensorflow.lite.python.util import get_tensor_name\n",
        "from tensorflow.lite.python.schema_py_generated import OperatorCode, BuiltinOperator\n",
        "\n",
        "def inspect_tflite_model(tflite_model_path):\n",
        "    # Load the TFLite model\n",
        "    with open(tflite_model_path, 'rb') as f:\n",
        "        model_data = f.read()\n",
        "\n",
        "    # Load model using the flatbuffer interpreter\n",
        "    interpreter = tf.lite.Interpreter(model_content=model_data)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Extract details\n",
        "    details = interpreter.get_tensor_details()\n",
        "\n",
        "    print(\"=== Operator List in TFLite Model ===\")\n",
        "    ops = interpreter._get_ops_details()\n",
        "\n",
        "    fallback_ops = set()\n",
        "\n",
        "    for i, op in enumerate(ops):\n",
        "        op_name = op['op_name']\n",
        "        if op_name.startswith('SELECT_TF_OP'):\n",
        "            fallback_ops.add(op_name)\n",
        "            print(f\" Op {i}: {op_name} (Fallback to TensorFlow)\")\n",
        "        else:\n",
        "            print(f\"Op {i}: {op_name} (TFLite Builtin)\")\n",
        "\n",
        "    if fallback_ops:\n",
        "        print(\"\\nModel includes TensorFlow fallback ops. This means full int8 quantization may not be achievable.\")\n",
        "    else:\n",
        "        print(\"\\n All operators are natively supported by TFLite. Good for deployment on microcontrollers!\")\n",
        "\n",
        "# inpsec the saved .tflite file\n",
        "inspect_tflite_model(os.path.join(save_dir, 'quantized_binary_plant_village.tflite'))\n"
      ],
      "metadata": {
        "id": "VxjULVUAVz0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare Original Keras vs Quantized TFLite (Size · Latency · Accuracy)\n",
        "\n",
        "**What this cell does**\n",
        "- **Loads models:**\n",
        "  - Original Keras model (`.keras`)\n",
        "  - Quantized TFLite model (`.tflite`)\n",
        "- **Builds a TFLite evaluator:**\n",
        "  - Creates an interpreter, feeds each test image, runs inference, and computes accuracy.\n",
        "- **Measures latency:**\n",
        "  - Uses wall-clock time to compute **seconds per sample** for both models.\n",
        "- **Checks model size:**\n",
        "  - Reports file sizes (KB) of the `.keras` and `.tflite` models.\n",
        "- **Prints a side-by-side comparison** of size, latency, and accuracy.\n",
        "\n",
        "**How accuracy is computed**\n",
        "- **Keras:** `model.evaluate(test_dataset)` returns accuracy directly.\n",
        "- **TFLite:** Iterates over `test_dataset.unbatch()`, runs `interpreter.invoke()`, applies `sigmoid` + `round` to get a binary prediction, and compares with labels.\n",
        "\n",
        "**How latency is measured**\n",
        "- Records start/end time around each evaluation loop and divides by the number of test samples to get **seconds/sample**.\n",
        "\n",
        "**Outputs you’ll see**\n",
        "1. **Model Size (KB)** for Keras vs TFLite  \n",
        "2. **Latency (s/sample)** for both models  \n",
        "3. **Accuracy** on the test set for both models\n",
        "\n",
        "**Notes**\n",
        "- If the TFLite model’s **input type is int8**, you typically need to quantize inputs using the interpreter’s input **scale** and **zero-point** from `input_details[0]['quantization']` rather than a raw cast to `int8`.  \n",
        "- Ensure test preprocessing (resize/normalize) matches training; mismatches can skew accuracy and latency.\n"
      ],
      "metadata": {
        "id": "R_KsF8KB2MHp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI0UBDkpRu4b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "# Load the original Keras model\n",
        "original_model = tf.keras.models.load_model(os.path.join(save_dir,'binary_plant_village.keras'))\n",
        "\n",
        "# Load the TFLite quantized model\n",
        "tflite_model_path = (os.path.join(save_dir,'quantized_binary_plant_village.tflite'))\n",
        "with open(tflite_model_path, 'rb') as f:\n",
        "    tflite_model = f.read()\n",
        "\n",
        "# Helper function to evaluate the TFLite model\n",
        "def evaluate_tflite_model(tflite_model, test_dataset):\n",
        "    # Initialize the TFLite interpreter\n",
        "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get input and output details\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    for image, label in test_dataset.unbatch():\n",
        "        # Preprocess the image\n",
        "        input_data = tf.cast(image, tf.int8 if input_details[0]['dtype'] == tf.int8 else tf.float32)\n",
        "        input_data = tf.expand_dims(input_data, axis=0)  # Add batch dimension\n",
        "\n",
        "        # Set the input tensor\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data.numpy())\n",
        "        interpreter.invoke()\n",
        "\n",
        "        # Get the prediction\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])\n",
        "        predicted_label = tf.round(tf.sigmoid(output)).numpy()[0][0]\n",
        "        if predicted_label == label.numpy():\n",
        "            correct_predictions += 1\n",
        "        total_samples += 1\n",
        "\n",
        "    # Calculate accuracy\n",
        "    return correct_predictions / total_samples\n",
        "\n",
        "# Evaluate the original model\n",
        "original_start_time = time.time()\n",
        "original_test_loss, original_test_acc = original_model.evaluate(test_dataset, verbose=0)\n",
        "original_latency = (time.time() - original_start_time) / len(list(test_dataset.unbatch()))\n",
        "original_size = os.path.getsize((os.path.join(save_dir,'mobilenet_finetuned_binary_plant_village.keras'))) / 1024  # in KB\n",
        "\n",
        "# Evaluate the TFLite model\n",
        "tflite_start_time = time.time()\n",
        "tflite_test_acc = evaluate_tflite_model(tflite_model, test_dataset)\n",
        "tflite_latency = (time.time() - tflite_start_time) / len(list(test_dataset.unbatch()))\n",
        "tflite_size = os.path.getsize(tflite_model_path) / 1024  # in KB\n",
        "\n",
        "# Print the comparison results\n",
        "print(f\"Model Comparison:\")\n",
        "print(f\"1. Model Size:\")\n",
        "print(f\"   - Original Model: {original_size:.2f} KB\")\n",
        "print(f\"   - TFLite Model: {tflite_size:.2f} KB\")\n",
        "print(f\"2. Latency (seconds per sample):\")\n",
        "print(f\"   - Original Model: {original_latency:.4f} s/sample\")\n",
        "print(f\"   - TFLite Model: {tflite_latency:.4f} s/sample\")\n",
        "print(f\"3. Accuracy on Test Data:\")\n",
        "print(f\"   - Original Model: {original_test_acc:.4f}\")\n",
        "print(f\"   - TFLite Model: {tflite_test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uCmQCereAu76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Sample Images & Export Quantized Int8 Arrays (TinyML-ready)\n",
        "\n",
        "### 1) Quantize images to Int8 using the TFLite model’s calibration\n",
        "- **Reads input quantization params** from the `.tflite`:\n",
        "  - `scale` (float), `zero_point` (int) via `interpreter.get_input_details()[0][\"quantization\"]`.\n",
        "- **Selects one sample per class** (`healthy`, `unhealthy`) directly from the dataset (already in **[0,1]**), resizes to **64×64**, and **quantizes to int8**:\n",
        "  - **Quantization formula:**  \n",
        "    `q = round(x / scale + zero_point)`  \n",
        "    then clip to `[-128, 127]` for `int8`.\n",
        "- **Exports a C header** `samples_one_per_class.h` with two arrays:\n",
        "  - `const int8_t healthy_64x64x3[12288]`\n",
        "  - `const int8_t unhealthy_64x64x3[12288]`\n",
        "- **Layout:** NHWC (row-major). `12288 = 64 × 64 × 3` elements (RGB).\n",
        "\n",
        "## Why quantization here (not a raw cast)?\n",
        "- A plain cast (`float32 → int8`) would distort values (most would become 0).\n",
        "- Using the model’s **(scale, zero_point)** ensures the integer inputs match what the model was **calibrated** to expect during post-training quantization.\n",
        "\n",
        "**Dequantize (what TFLite does internally):**  \n",
        "`real ≈ scale × (q − zero_point)`\n",
        "\n",
        "**Quantize (what we do for input):**  \n",
        "`q = round(real / scale + zero_point)`\n",
        "\n",
        "\n",
        "## Outputs you’ll see\n",
        "1. **Saved JPEGs** under `healthy/` and `unhealthy/`.\n",
        "2. Console printouts of the model’s **input dtype** and **(scale, zero_point)**.\n",
        "3. A header file: **`samples_one_per_class.h`** containing two `int8_t` arrays ready for Arduino/TFLite Micro.\n",
        "\n",
        "\n",
        "## Notes & tips\n",
        "- Keep preprocessing identical to training (e.g., if you used `/255.0`, do that before quantization).\n",
        "- The arrays are **signed int8**; if your model expects `uint8`, adjust accordingly.\n",
        "\n"
      ],
      "metadata": {
        "id": "V_TjcnDgAw44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, numpy as np, tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === Inputs you already have ===\n",
        "# - train_dataset: a tf.data.Dataset yielding (image, label) with labels {0: healthy, 1: unhealthy}\n",
        "# - tflite_model_path: path to your quantized .tflite\n",
        "\n",
        "TARGET_SIZE = (64, 64)  # adjust if your model expects a different size\n",
        "tflite_model_path = os.path.join(save_dir, \"quantized_binary_plant_village.tflite\")\n",
        "\n",
        "# 1) Read input quantization (scale, zero_point) from the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()[0]\n",
        "in_scale, in_zero = input_details[\"quantization\"]  # (scale, zero_point)\n",
        "\n",
        "print(\"TFLite input quantization:\", (in_scale, in_zero))\n",
        "print(\"Expected input dtype:\", input_details[\"dtype\"], \"shape:\", input_details[\"shape\"])\n",
        "\n",
        "# 2) Choose the preprocessing that matches your *float* model input before quantization\n",
        "#    If your model expects [0,1] floats (common when you used Rescaling(1/255) or manual /255):\n",
        "def preprocess_float(x):\n",
        "    # If your dataset already yields [0,1] floats, leave as-is.\n",
        "    # If dataset is uint8 [0,255], uncomment the next line:\n",
        "    # x = x / 255.0\n",
        "    return x\n",
        "\n",
        "# 3) Pick 2 samples from each class (0 = healthy, 1 = unhealthy)\n",
        "def collect_two_per_class(dataset):\n",
        "    got = {0: [], 1: []}\n",
        "    for img, lab in dataset.unbatch():\n",
        "        lab = int(lab.numpy())\n",
        "        if len(got[lab]) < 2:\n",
        "            # Resize to target size\n",
        "            img = tf.image.resize(img, TARGET_SIZE, method=\"bilinear\")\n",
        "            got[lab].append(img.numpy())\n",
        "        if len(got[0]) == 2 and len(got[1]) == 2:\n",
        "            break\n",
        "    if len(got[0]) < 2 or len(got[1]) < 2:\n",
        "        raise ValueError(\"Not enough samples found for one of the classes.\")\n",
        "    return got\n",
        "\n",
        "samples = collect_two_per_class(train_dataset)  # {0: [img0,img1], 1: [img0,img1]}\n",
        "\n",
        "# 4) Quantize to int8 using scale/zero-point (NHWC)\n",
        "def float_to_int8(nhwc_float, scale, zero):\n",
        "    # nhwc_float should be the float *input domain* your model expects (often [0,1])\n",
        "    q = np.round(nhwc_float / scale + zero)\n",
        "    q = np.clip(q, -128, 127).astype(np.int8)\n",
        "    return q\n",
        "\n",
        "# 5) Show images + print arrays; also accumulate for a .h file\n",
        "def show_and_prepare(arr, title):\n",
        "    plt.figure()\n",
        "    # For visualization, clip to [0,1] if you used that range; otherwise normalize for display\n",
        "    vis = preprocess_float(arr.copy())\n",
        "    vis = np.clip(vis, 0.0, 1.0)\n",
        "    plt.imshow(vis.astype(np.float32))\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "arrays_c = []  # (name, int8_array_flat, shape)\n",
        "names = []\n",
        "\n",
        "for cls, name_prefix in [(0, \"healthy\"), (1, \"unhealthy\")]:\n",
        "    for i, img in enumerate(samples[cls]):\n",
        "        f32 = preprocess_float(img.astype(np.float32))            # HxWxC float\n",
        "        q8  = float_to_int8(f32, in_scale, in_zero)               # HxWxC int8\n",
        "        show_and_prepare(f32, f\"{name_prefix} #{i} (display)\")\n",
        "        flat = q8.flatten()\n",
        "        var_name = f\"{name_prefix}_{i}_64x64x3_int8\"\n",
        "        arrays_c.append((var_name, flat, q8.shape))\n",
        "        names.append(var_name)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# 6) Print full arrays (int8) to the notebook\n",
        "for var_name, flat, shape in arrays_c:\n",
        "    print(f\"\\n// {var_name} shape {shape}, length {flat.size}\")\n",
        "    # Print as comma-separated values\n",
        "    # (Comment out if too long)\n",
        "    print(\"{\")\n",
        "    # chunk printing for readability\n",
        "    for s in range(0, flat.size, 32):\n",
        "        line = \", \".join(str(int(v)) for v in flat[s:s+32])\n",
        "        print(\"  \" + line + (\",\" if s + 32 < flat.size else \"\"))\n",
        "    print(\"}\")\n",
        "\n",
        "# 7) Write a C header you can include in Arduino projects\n",
        "header_path = os.path.join(save_dir, \"samples_int8.h\")\n",
        "with open(header_path, \"w\") as f:\n",
        "    f.write(\"#pragma once\\n#include <stdint.h>\\n\\n\")\n",
        "    f.write(\"// Quantization: x_int8 = round(x_float/scale + zero_point)\\n\")\n",
        "    f.write(f\"// scale = {in_scale:.8g}, zero_point = {int(in_zero)}\\n\")\n",
        "    f.write(f\"// layout = NHWC, size = {TARGET_SIZE[0]}x{TARGET_SIZE[1]}x3\\n\\n\")\n",
        "    for var_name, flat, shape in arrays_c:\n",
        "        f.write(f\"// {var_name} shape {shape}\\n\")\n",
        "        f.write(f\"const int8_t {var_name}[{flat.size}] = {{\\n\")\n",
        "        for s in range(0, flat.size, 32):\n",
        "            line = \", \".join(str(int(v)) for v in flat[s:s+32])\n",
        "            f.write(\"  \" + line + (\",\" if s + 32 < flat.size else \"\") + \"\\n\")\n",
        "        f.write(\"};\\n\\n\")\n",
        "print(\"Saved header:\", header_path)\n",
        "\n",
        "# (Optional) Also save each array as a .npy if you want to load later:\n",
        "# for var_name, flat, shape in arrays_c:\n",
        "#     np.save(os.path.join(save_dir, f\"{var_name}.npy\"), flat.reshape(shape))\n"
      ],
      "metadata": {
        "id": "2WPjAJEN43u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, numpy as np, tensorflow as tf\n",
        "\n",
        "TARGET_SIZE = (64, 64)\n",
        "tflite_model_path = os.path.join(save_dir, \"quantized_binary_plant_village.tflite\")\n",
        "\n",
        "# Read input quantization\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "interpreter.allocate_tensors()\n",
        "inp = interpreter.get_input_details()[0]\n",
        "in_scale, in_zero = inp[\"quantization\"]          # (scale, zero_point)\n",
        "in_dtype = inp[\"dtype\"]                          # np.int8 / np.uint8 / np.float32\n",
        "\n",
        "if in_dtype == np.int8:\n",
        "    clip_lo, clip_hi = -128, 127\n",
        "    c_type = \"int8_t\"\n",
        "elif in_dtype == np.uint8:\n",
        "    clip_lo, clip_hi = 0, 255\n",
        "    c_type = \"uint8_t\"\n",
        "else:\n",
        "    raise ValueError(\"Model input is float32; no quantization needed. (Change model or skip header.)\")\n",
        "\n",
        "def float_to_q(nhwc_float):\n",
        "    # nhwc_float is already in [0,1] as you said\n",
        "    q = np.round(nhwc_float / in_scale + in_zero)\n",
        "    return np.clip(q, clip_lo, clip_hi).astype(in_dtype)\n",
        "\n",
        "def collect_one_per_class(dataset):\n",
        "    got = {0: None, 1: None}  # 0=healthy, 1=unhealthy\n",
        "    for img, lab in dataset.unbatch():\n",
        "        lab = int(lab.numpy())\n",
        "        if got[lab] is None:\n",
        "            # resize to model input\n",
        "            img = tf.image.resize(img, TARGET_SIZE, method=\"bilinear\")\n",
        "            got[lab] = img.numpy().astype(np.float32)  # already [0,1]\n",
        "            if got[0] is not None and got[1] is not None:\n",
        "                break\n",
        "    if got[0] is None or got[1] is None:\n",
        "        raise ValueError(\"Couldn't find one sample per class.\")\n",
        "    return got[0], got[1]\n",
        "\n",
        "healthy_f32, unhealthy_f32 = collect_one_per_class(train_dataset)\n",
        "healthy_q = float_to_q(healthy_f32)       # (64,64,3)\n",
        "unhealthy_q = float_to_q(unhealthy_f32)\n",
        "\n",
        "# Write a header with exactly two arrays\n",
        "header_path = os.path.join(save_dir, \"samples_one_per_class.h\")\n",
        "with open(header_path, \"w\") as f:\n",
        "    f.write(\"#pragma once\\n#include <stdint.h>\\n\\n\")\n",
        "    f.write(\"// Input quantization: q = round(x/scale + zero_point)\\n\")\n",
        "    f.write(f\"// scale = {in_scale:.8g}, zero_point = {int(in_zero)}, dtype = {c_type}\\n\")\n",
        "    f.write(f\"// layout = NHWC, size = {TARGET_SIZE[0]}x{TARGET_SIZE[1]}x3\\n\\n\")\n",
        "    for name, arr in [(\"healthy_64x64x3\", healthy_q), (\"unhealthy_64x64x3\", unhealthy_q)]:\n",
        "        flat = arr.flatten()\n",
        "        f.write(f\"const {c_type} {name}[{flat.size}] = {{\\n\")\n",
        "        for s in range(0, flat.size, 32):\n",
        "            line = \", \".join(str(int(v)) for v in flat[s:s+32])\n",
        "            f.write(\"  \" + line + (\",\" if s + 32 < flat.size else \"\") + \"\\n\")\n",
        "        f.write(\"};\\n\\n\")\n",
        "\n",
        "print(\"Saved header:\", header_path)\n"
      ],
      "metadata": {
        "id": "tC-Zeoxf4_18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the `.tflite` file into a C/C++ Array for Firmware\n",
        "\n",
        "## Why do this?\n",
        "On many microcontrollers you can’t read files from a filesystem. Converting your TensorFlow Lite model (`.tflite`) into a C/C++ byte array lets you **compile the model into your firmware** so it lives in program memory (flash) and can be passed directly to TFLite Micro.\n",
        "\n",
        ".cc file wil contain something like this\n",
        "unsigned char quantized_binary_plant_village_tflite[] = { 0x1c, 0x00, 0x00, ... };\n",
        "unsigned int quantized_binary_plant_village_tflite_len = 123456;\n"
      ],
      "metadata": {
        "id": "SWcFx4KvCAuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!xxd -i /content/drive/My\\ Drive/TinyPlants/quantized_binary_plant_village.tflite > model.cc\n"
      ],
      "metadata": {
        "id": "iITnJi8QXiXg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}